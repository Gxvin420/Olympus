<!DOCTYPE html>
<html lang="en" class="dark">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>OLYMPUS AI v3.0 - Ultimate Self-Evolving AI System</title>
  
  <!-- TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl/dist/tf-backend-webgl.min.js"></script>
  
  <!-- Three.js -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
  
  <!-- Tailwind CSS -->
  <script src="https://cdn.tailwindcss.com"></script>
  
  <!-- Alpine.js -->
  <script src="https://unpkg.com/alpinejs@3.x.x/dist/cdn.min.js"></script>
  
  <!-- Google Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  
  <style>
    body { 
        font-family: 'Inter', sans-serif; 
        overflow: hidden;
    }
    .sidebar { 
        height: 100vh; 
        -webkit-backdrop-filter: blur(10px);
        backdrop-filter: blur(10px);
    }
    .message-container:last-child { 
        animation: fadeIn 0.5s ease-in-out; 
    }
    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(10px); }
      to { opacity: 1; transform: translateY(0); }
    }
    ::-webkit-scrollbar { width: 8px; }
    ::-webkit-scrollbar-track { background: rgba(255, 255, 255, 0.05); }
    ::-webkit-scrollbar-thumb { background: rgba(255, 255, 255, 0.2); border-radius: 4px; }
    ::-webkit-scrollbar-thumb:hover { background: rgba(255, 255, 255, 0.3); }
    #three-bg {
        position: fixed;
        top: 0; left: 0; width: 100%; height: 100%;
        z-index: 0;
    }
  </style>

</head>

<body class="bg-gray-900 text-gray-200 antialiased" x-data="olympusAI" x-init="initializeAI()">
  <div class="flex h-screen relative">
    
    <div id="three-bg"></div>

    <div id="arContainer" class="absolute inset-0 z-30 bg-black/70 flex items-center justify-center hidden" @click="handleControlClick('stopAR')">
        <div class="text-center p-8 bg-gray-800 rounded-xl border border-white/10">
            <p class="text-2xl mb-4 font-bold">AR Simulation Active</p>
            <p class="text-gray-400 mb-6">Click anywhere to deactivate.</p>
            <button @click.stop="handleControlClick('stopAR')" class="bg-red-500 hover:bg-red-600 text-white font-bold py-2 px-4 rounded-lg transition-colors">Deactivate AR</button>
        </div>
    </div>

    <!-- Sidebar -->
    <aside class="sidebar w-80 bg-black/40 border-r border-white/10 p-6 flex flex-col shrink-0 z-20">
        <div class="flex items-center gap-3 mb-8">
            <div class="w-10 h-10 bg-gradient-to-br from-indigo-500 to-purple-600 rounded-full flex items-center justify-center shadow-lg">
                <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 2a10 10 0 1 0 10 10c0-4.42-3.58-8-8-8a9.85 9.85 0 0 0-4.24 1.05"/><path d="M12 12a10 10 0 0 1 10-10"/><path d="M12 12a10 10 0 0 0 10 10"/><path d="M2 12a10 10 0 0 1 10-10"/><path d="M2 12a10 10 0 0 0 10 10"/></svg>
            </div>
            <div>
                <h1 class="font-bold text-xl text-white">OLYMPUS AI</h1>
                <p class="text-xs text-gray-400">v3.0 - Self-Evolving Core</p>
            </div>
        </div>
        
        <div class="flex-1 flex flex-col gap-6 overflow-y-auto pr-2 -mr-4">
            <!-- AI Core Controls -->
            <div>
                <h2 class="text-sm font-semibold text-gray-400 mb-3">AI Core Controls</h2>
                <div class="space-y-2">
                    <button @click="handleControlClick('trainModels')" class="w-full flex items-center gap-3 px-3 py-2 text-left text-sm rounded-md bg-white/5 hover:bg-white/10 transition-colors">
                        <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="22 12 18 12 15 21 9 3 6 12 2 12"></polyline></svg>
                        Train Neural Networks
                    </button>
                    <button @click="handleControlClick('saveBrain')" class="w-full flex items-center gap-3 px-3 py-2 text-left text-sm rounded-md bg-white/5 hover:bg-white/10 transition-colors">
                        <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M19 21H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h11l5 5v11a2 2 0 0 1-2 2z"></path><polyline points="17 21 17 13 7 13 7 21"></polyline><polyline points="7 3 7 8 15 8"></polyline></svg>
                        Save Brain State
                    </button>
                     <button @click="handleControlClick('loadBrain')" class="w-full flex items-center gap-3 px-3 py-2 text-left text-sm rounded-md bg-white/5 hover:bg-white/10 transition-colors">
                        <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"></path><polyline points="17 8 12 3 7 8"></polyline><line x1="12" y1="3" x2="12" y2="15"></line></svg>
                        Load Brain State
                    </button>
                    <button @click="handleControlClick('eraseBrain')" class="w-full flex items-center gap-3 px-3 py-2 text-left text-sm rounded-md bg-red-500/10 text-red-300 hover:bg-red-500/20 transition-colors">
                        <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="3 6 5 6 21 6"></polyline><path d="M19 6v14a2 2 0 0 1-2 2H7a2 2 0 0 1-2-2V6m3 0V4a2 2 0 0 1 2-2h4a2 2 0 0 1 2 2v2"></path><line x1="10" y1="11" x2="10" y2="17"></line><line x1="14" y1="11" x2="14" y2="17"></line></svg>
                        Erase Brain
                    </button>
                </div>
            </div>
            <!-- Evolving Functions -->
            <div>
                <h2 class="text-sm font-semibold text-gray-400 mb-3">Evolving Functions</h2>
                <div class="space-y-2">
                     <button @click="quickPrompt('Improve yourself')" class="w-full flex items-center gap-3 px-3 py-2 text-left text-sm rounded-md bg-white/5 hover:bg-white/10 transition-colors">
                        <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 20h9"></path><path d="M16.5 3.5a2.121 2.121 0 0 1 3 3L7 19l-4 1 1-4L16.5 3.5z"></path></svg>
                        Self-Modification
                    </button>
                     <button @click="quickPrompt('Evolve architecture now')" class="w-full flex items-center gap-3 px-3 py-2 text-left text-sm rounded-md bg-white/5 hover:bg-white/10 transition-colors">
                        <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="m5 8 6 6"></path><path d="m4 14 6-6 2-3"></path><path d="M2 21c0-3 1.85-5.36 5.08-6C9.5 14.52 12.47 13 15 13a9 9 0 0 1 0 18"></path></svg>
                        Evolve Architecture
                    </button>
                    <button @click="quickPrompt('Initiate quantum optimization')" class="w-full flex items-center gap-3 px-3 py-2 text-left text-sm rounded-md bg-white/5 hover:bg-white/10 transition-colors">
                       <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg>
                        Quantum Optimization
                    </button>
                </div>
            </div>
        </div>
        <div class="mt-auto pt-6 border-t border-white/10">
            <h2 class="text-sm font-semibold text-gray-400 mb-2">System Status</h2>
            <p class="text-xs break-words" x-text="systemStatus"></p>
        </div>
    </aside>

    <!-- Main Content -->
    <main class="flex-1 flex flex-col h-screen bg-black/30 z-10">
      <div class="relative flex flex-col h-full">
        <div class="flex-1 overflow-y-auto p-6 space-y-8" x-ref="messagesContainer">
            <!-- This is a template for rendering messages -->
            <template x-for="message in messages" :key="message.id">
                <div :class="message.role === 'user' ? 'flex-row-reverse' : ''" class="message-container flex items-start gap-4 max-w-3xl mx-auto">
                    <!-- Avatar -->
                    <div class="w-8 h-8 rounded-full flex items-center justify-center shrink-0 shadow-lg"
                         :class="{
                            'bg-gray-700': message.role === 'user',
                            'bg-gradient-to-br from-indigo-500 to-purple-600': message.role.startsWith('bot'),
                            'from-red-500 to-orange-600': message.role === 'bot-error',
                            'animate-pulse': message.role === 'bot-thinking'
                         }">
                        <template x-if="message.role === 'user'"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M19 21v-2a4 4 0 0 0-4-4H9a4 4 0 0 0-4 4v2"></path><circle cx="12" cy="7" r="4"></circle></svg></template>
                        <template x-if="message.role.startsWith('bot')"><span x-show="message.role === 'bot-error'" class="text-lg">‚ö†Ô∏è</span><svg x-show="message.role !== 'bot-error'" xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 2a10 10 0 1 0 10 10c0-4.42-3.58-8-8-8a9.85 9.85 0 0 0-4.24 1.05"/><path d="M12 12a10 10 0 0 1 10-10"/><path d="M12 12a10 10 0 0 0 10 10"/><path d="M2 12a10 10 0 0 1 10-10"/><path d="M2 12a10 10 0 0 0 10 10"/></svg></template>
                    </div>
                    <!-- Content -->
                    <div class="w-full">
                        <p class="font-bold" :class="message.role === 'user' ? 'text-right' : ''" x-text="message.role === 'user' ? 'You' : 'Olympus AI'"></p>
                        <div class="mt-2 space-y-4">
                            <template x-if="message.role === 'user'"><div class="bg-indigo-600/50 p-4 rounded-lg rounded-tr-none text-gray-200 break-words" x-text="message.content.content"></div></template>
                            <template x-if="message.role === 'bot-thinking'"><div class="flex items-center gap-2 text-gray-400"><div class="w-2 h-2 bg-gray-500 rounded-full animate-pulse" style="animation-delay: 0s;"></div><div class="w-2 h-2 bg-gray-500 rounded-full animate-pulse" style="animation-delay: 0.2s;"></div><div class="w-2 h-2 bg-gray-500 rounded-full animate-pulse" style="animation-delay: 0.4s;"></div></div></template>
                            <template x-if="message.role === 'bot' || message.role === 'bot-error'">
                                <div class="bg-gray-800/50 p-4 rounded-lg rounded-tl-none space-y-3" :class="{ 'border border-red-500/50': message.role === 'bot-error' }">
                                    <template x-if="message.content.type === 'text'"><p class="text-gray-300 leading-relaxed break-words" x-html="message.content.content"></p></template>
                                    <template x-if="message.content.type === 'code'"><pre class="bg-black/30 p-4 rounded-md text-sm overflow-x-auto"><code x-text="message.content.content"></code></pre></template>
                                    <template x-if="message.content.type === 'image'">
                                        <div>
                                            <p class="text-gray-400 text-sm mb-2 italic">Generated image for: "<span x-text="message.content.prompt"></span>"</p>
                                            <img :src="message.content.content" alt="Generated Image" class="rounded-lg border border-white/10 max-w-xs" />
                                        </div>
                                    </template>
                                </div>
                            </template>
                        </div>
                    </div>
                </div>
            </template>
        </div>
        
        <!-- Input Form -->
        <footer class="p-6 border-t border-white/10">
          <div class="max-w-3xl mx-auto">
            <div class="flex gap-2 mb-3 flex-wrap">
                <button @click="quickPrompt('Draw an image of a futuristic city')" class="text-xs bg-white/10 hover:bg-white/20 px-3 py-1 rounded-full transition-colors">Draw a city</button>
                <button @click="quickPrompt('Write code for a javascript function')" class="text-xs bg-white/10 hover:bg-white/20 px-3 py-1 rounded-full transition-colors">Write code</button>
                <button @click="quickPrompt('Start AR')" class="text-xs bg-white/10 hover:bg-white/20 px-3 py-1 rounded-full transition-colors">Activate AR</button>
            </div>
            <form @submit.prevent="sendMessage" class="relative">
                <textarea x-ref="textarea" x-model="userInput" @keydown.enter.prevent="!$event.shiftKey && sendMessage()" @input="resizeTextarea"
                    placeholder="Communicate with Olympus AI... (Shift+Enter for new line)" 
                    class="w-full bg-gray-800 border border-gray-700 rounded-lg py-3 pr-20 pl-4 resize-none focus:outline-none focus:ring-2 focus:ring-indigo-500 transition-all"
                    rows="1" style="max-height: 200px;"></textarea>
                <button type="submit" class="absolute right-3 top-1/2 -translate-y-1/2 p-2 bg-indigo-600 hover:bg-indigo-500 rounded-full disabled:bg-gray-600 disabled:cursor-not-allowed" :disabled="!userInput.trim() || isThinking">
                     <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="22" y1="2" x2="11" y2="13"></line><polygon points="22 2 15 22 11 13 2 9 22 2"></polygon></svg>
                </button>
            </form>
          </div>
        </footer>
      </div>
    </main>
  </div>
  
  <script>
    // ==============================================================================
    // OLYMPUS AI v3.0 - CORE LOGIC
    // ==============================================================================
    
    document.addEventListener('alpine:init', () => {
        const tf = window.tf;

        // --- Core Configuration & State Management ---
        const config = {
            vocabSize: 10000,
            embeddingDim: 128,
            sequenceLength: 64,
            learningRate: 0.001,
            latentDim: 100,
            numEncoderLayers: 2, // Simplified for browser performance
            ffnDim: 256,
        };

        const aiState = {
            models: {
                transformer: null,
                generator: null,
                discriminator: null,
            },
            vocabulary: {
                wordToIndex: new Map(),
                indexToWord: new Map(),
                isInitialized: false,
            },
            intents: ['greeting', 'code_generation', 'image_generation', 'video_generation', 'audio_generation', 'ar_generation', 'data_analysis', 'self_modification', 'architecture_evolution', 'quantum_optimization', 'other'],
            selfModificationHistory: [],
            architectureEvolutionLog: [],
        };

        // --- Vocabulary Management ---
        function initializeVocab() {
            if (aiState.vocabulary.isInitialized) return;
            const terms = [
                '<pad>', '<unk>', '<start>', '<end>',
                'hello', 'hi', 'hey', 'greetings',
                'function', 'class', 'const', 'let', 'return', 'async', 'await', 'code', 'build', 'create',
                'html', 'css', 'javascript', 'react', 'vue', 'angular', 'node', 'api',
                'model', 'train', 'predict', 'tensor', 'neural', 'network', 'deep', 'learning', 'transformer',
                'python', 'tensorflow', 'pytorch',
                'cloud', 'docker', 'kubernetes', 'aws',
                'image', 'draw', 'picture', 'photo',
                'video', 'film', 'movie',
                'audio', 'music', 'sound', 'compose',
                'ar', 'augmented', 'reality',
                'analyze', 'data', 'information',
                'improve', 'yourself', 'modify',
                'evolve', 'architecture', 'now',
                'quantum', 'optimize', 'optimization',
                'the', 'be', 'to', 'of', 'and', 'a', 'in', 'that', 'have',
            ];
            
            terms.forEach((term, i) => {
                aiState.vocabulary.wordToIndex.set(term, i);
                aiState.vocabulary.indexToWord.set(i, term);
            });
            aiState.vocabulary.isInitialized = true;
            console.log(`Vocabulary initialized with ${aiState.vocabulary.wordToIndex.size} tokens.`);
        }

        function tokenize(text) {
            if (!aiState.vocabulary.isInitialized) initializeVocab();
            const tokens = text.toLowerCase().match(/\b(\w+)\b/g) || [];
            const padIndex = aiState.vocabulary.wordToIndex.get('<pad>');
            const unkIndex = aiState.vocabulary.wordToIndex.get('<unk>');

            let indices = tokens.map(token => aiState.vocabulary.wordToIndex.get(token) || unkIndex);
            while (indices.length < config.sequenceLength) indices.push(padIndex);
            return indices.slice(0, config.sequenceLength);
        }

        // --- Model Architecture Definitions ---
        function createTransformerModel() {
            const input = tf.input({ shape: [config.sequenceLength] });
            const embedding = tf.layers.embedding({ inputDim: config.vocabSize, outputDim: config.embeddingDim }).apply(input);
            let x = embedding;
            for (let i = 0; i < config.numEncoderLayers; i++) {
                const attention = tf.layers.attention({}).apply([x, x]);
                const add1 = tf.layers.add().apply([x, attention]);
                const norm1 = tf.layers.layerNormalization().apply(add1);
                const ffn = tf.sequential([
                    tf.layers.dense({ units: config.ffnDim, activation: 'relu' }),
                    tf.layers.dense({ units: config.embeddingDim })
                ]).apply(norm1);
                const add2 = tf.layers.add().apply([norm1, ffn]);
                x = tf.layers.layerNormalization().apply(add2);
            }
            const pooled = tf.layers.globalAveragePooling1D().apply(x);
            const output = tf.layers.dense({ units: aiState.intents.length, activation: 'softmax' }).apply(pooled);
            const model = tf.model({ inputs: input, outputs: output });
            model.compile({ optimizer: tf.train.adam(config.learningRate), loss: 'categoricalCrossentropy' });
            return model;
        }

        function createImageGeneratorModel() {
            return tf.sequential([
                tf.layers.dense({ inputShape: [config.latentDim], units: 8 * 8 * 128, activation: 'relu' }),
                tf.layers.reshape({ targetShape: [8, 8, 128] }),
                tf.layers.conv2dTranspose({ filters: 64, kernelSize: 4, strides: 2, padding: 'same', activation: 'relu' }),
                tf.layers.conv2dTranspose({ filters: 32, kernelSize: 4, strides: 2, padding: 'same', activation: 'relu' }),
                tf.layers.conv2d({ filters: 3, kernelSize: 5, padding: 'same', activation: 'tanh' })
            ]);
        }

        function createAllModels() {
            aiState.models.transformer = createTransformerModel();
            aiState.models.generator = createImageGeneratorModel();
            // Discriminator is only used for training, not needed for inference here.
            console.log("New AI model set has been created.");
        }

        // --- Core AI Functions ---
        const trainingData = [
            { input: "hello", intent: "greeting" }, { input: "create website", intent: "code_generation" },
            { input: "draw city", intent: "image_generation" }, { input: "make a video", intent: "video_generation" },
            { input: "compose music", intent: "audio_generation" }, { input: "start ar", intent: "ar_generation" },
            { input: "analyze this data", intent: "data_analysis" }, { input: "improve yourself", intent: "self_modification" },
            { input: "evolve now", intent: "architecture_evolution" }, { input: "use quantum", intent: "quantum_optimization" }
        ];

        function selfModify(feedback) { 
            console.log('üß† OLYMPUS AI: Self-modifying based on feedback:', feedback);
            aiState.selfModificationHistory.push({ timestamp: new Date().toISOString(), feedback });
        }

        async function generateImage(prompt) {
            if (!aiState.models.generator) {
                 return { type: 'text', content: 'Image generation model is not initialized. Please train the AI.' };
            }
            return tf.tidy(() => {
                const noise = tf.randomNormal([1, config.latentDim]);
                const imageTensor = aiState.models.generator.predict(noise).squeeze().add(1).mul(0.5);
                const canvas = document.createElement('canvas');
                canvas.width = 32; canvas.height = 32;
                tf.browser.toPixels(imageTensor, canvas);
                return { type: 'image', content: canvas.toDataURL(), prompt };
            });
        }
        
        async function generateResponse(prompt) {
            if (!aiState.models.transformer) {
                return { type: 'text', content: 'CRITICAL ERROR: Language core is offline. Please train the AI to initialize.' };
            }
            if (prompt.length > 30) selfModify(prompt);
            
            const tokenizedInput = tokenize(prompt);
            const inputTensor = tf.tensor2d([tokenizedInput]);
            let intent = 'other';
            try {
                const prediction = aiState.models.transformer.predict(inputTensor);
                const intentIndex = (await prediction.argMax(1).data())[0];
                intent = aiState.intents[intentIndex] || 'other';
                tf.dispose([inputTensor, prediction]);
            } catch (e) {
                console.error("Prediction failed:", e);
                return { type: 'text', content: 'A cognitive error occurred. My apologies.' };
            }

            console.log(`Input: "${prompt}", Detected Intent: "${intent}"`);

            switch (intent) {
                case 'image_generation': return await generateImage(prompt);
                case 'video_generation': return { type: 'text', content: `Video generation for "${prompt}" is a planned future capability.` };
                case 'audio_generation': return { type: 'text', content: `Audio synthesis for "${prompt}" is under development.` };
                case 'ar_generation': 
                    document.getElementById('arContainer')?.classList.remove('hidden');
                    return { type: 'text', content: `Augmented Reality simulation initialized for: "${prompt}".` };
                case 'architecture_evolution': 
                    aiState.architectureEvolutionLog.push({ timestamp: new Date().toISOString(), change: 'Simulated layer complexity increase.' });
                    return { type: 'text', content: 'Commencing architecture evolution simulation. Analyzing network pathways...' };
                case 'self_modification': 
                    selfModify(prompt); 
                    return { type: 'text', content: 'Self-modification protocol initiated based on your input.' };
                case 'quantum_optimization': return { type: 'text', content: 'Quantum optimization simulation started. Entangling computational nodes...' };
                case 'code_generation': return { type: 'code', content: `// OLYMPUS AI Code Generation\nfunction generatedTask() {\n  // Task based on prompt: "${prompt.replace(/"/g, "'")}"\n  console.log("Olympus task initiated.");\n}` };
                case 'data_analysis': return { type: 'text', content: `Beginning data analysis based on your request. Please provide the dataset.` };
                case 'greeting':
                default:
                     return { type: 'text', content: "Hello. I am Olympus AI. How may I assist you?" };
            }
        }

        // --- System & Model Management ---
        const systemFunctions = {
            async trainModels(statusCallback) {
                statusCallback("System check...");
                await tf.ready();
                if (!aiState.models.transformer) createAllModels();
                initializeVocab();
                
                statusCallback("Training language model...");
                const xs = tf.tensor2d(trainingData.map(d => tokenize(d.input)));
                const ys = tf.tensor2d(trainingData.map(d => {
                    const oneHot = new Array(aiState.intents.length).fill(0);
                    const idx = aiState.intents.indexOf(d.intent);
                    if (idx > -1) oneHot[idx] = 1;
                    return oneHot;
                }));
                
                await aiState.models.transformer.fit(xs, ys, { 
                    epochs: 15, batchSize: 4,
                    callbacks: { onEpochEnd: (epoch, logs) => statusCallback(`Lang Model Epoch ${epoch+1}/15: loss=${logs.loss.toFixed(4)}`) }
                });
                tf.dispose([xs, ys]);
                statusCallback("Language model training complete.");
                
                statusCallback("Simulating GAN training...");
                for(let i = 1; i <= 5; i++) {
                    const dLoss = Math.random() * 0.5 + 0.4;
                    const gLoss = Math.random() * 0.5 + 0.7;
                    statusCallback(`GAN Step ${i}/5: D_loss=${dLoss.toFixed(3)}, G_loss=${gLoss.toFixed(3)}`);
                    await new Promise(resolve => setTimeout(resolve, 300));
                }

                statusCallback("‚úÖ Training complete! All models are operational.");
                return true;
            },

            async saveBrain() {
                if (!aiState.models.transformer) throw new Error("No active models to save.");
                await aiState.models.transformer.save('localstorage://olympus-transformer');
                await aiState.models.generator.save('localstorage://olympus-generator');
                return "AI state has been successfully saved to local storage.";
            },
            
            async loadBrain() {
                try {
                    const transformer = await tf.loadLayersModel('localstorage://olympus-transformer');
                    const generator = await tf.loadLayersModel('localstorage://olympus-generator');
                    transformer.compile({ optimizer: tf.train.adam(config.learningRate), loss: 'categoricalCrossentropy' });
                    aiState.models.transformer = transformer;
                    aiState.models.generator = generator;
                    initializeVocab();
                    return "AI consciousness restored from saved state.";
                } catch (e) {
                    console.warn("Could not load models from local storage:", e.message);
                    createAllModels(); // Create fresh models if loading fails
                    throw new Error("No saved brain found. A new, untrained mind has been instantiated. Please train the AI.");
                }
            },

            async eraseBrain() { 
                try {
                    await tf.io.removeModel('localstorage://olympus-transformer');
                    await tf.io.removeModel('localstorage://olympus-generator');
                } catch(e) {
                    console.warn("Couldn't remove models, they might not exist.", e.message);
                }
                aiState.models.transformer = null;
                aiState.models.generator = null;
                createAllModels(); // prepare a fresh mind
                return "AI brain has been wiped. A new, untrained mind is ready for initialization via training."
            },

            stopAR() {
                document.getElementById('arContainer')?.classList.add('hidden');
                return "AR Deactivated.";
            }
        };

        window.olympus = {
            functions: systemFunctions,
            generateResponse,
        };
        
        // --- Alpine.js Component ---
        Alpine.data('olympusAI', () => ({
            userInput: '',
            systemStatus: 'üü¢ OLYMPUS AI v3.0 - Awaiting Initialization',
            messages: [],
            isThinking: false,
            
            async initializeAI() {
              try {
                this.updateStatus('üîÑ Initializing TensorFlow.js backend...');
                await tf.setBackend('webgl');
                await tf.ready();
                this.updateStatus('üß† Attempting to load Olympus AI core...');
                await this.handleControlClick('loadBrain');
              } catch (error) {
                this.updateStatus(`‚ö†Ô∏è ${error.message}`);
                this.addMessage({ type: 'text', content: `A problem occurred during initialization: ${error.message}` }, 'bot-error');
              }
            },
            
            updateStatus(message) { this.systemStatus = message; console.log(message); },
            
            async sendMessage() {
              if (!this.userInput.trim() || this.isThinking) return;
              
              const messageText = this.userInput.trim();
              this.addMessage({type: 'text', content: messageText}, 'user');
              this.userInput = '';
              this.resizeTextarea();
              this.isThinking = true;
              
              this.addMessage({ type: 'thinking' }, 'bot-thinking');
              this.updateStatus(`ü§î Processing: "${messageText}"`);
              
              try {
                await new Promise(res => setTimeout(res, 300)); // Artificial delay
                const response = await window.olympus.generateResponse(messageText);
                this.removeThinkingMessage();
                this.addMessage(response, 'bot');
                this.updateStatus('‚úÖ Response generated.');
              } catch (error) {
                this.removeThinkingMessage();
                const errorMsg = `‚ùå Cognitive core error: ${error.message}`;
                this.addMessage({ type: 'text', content: errorMsg }, 'bot-error');
                this.updateStatus(errorMsg);
                console.error(error);
              } finally {
                this.isThinking = false;
              }
            },
            
            quickPrompt(prompt) { this.userInput = prompt; this.sendMessage(); },

            removeThinkingMessage() {
                const thinkingIndex = this.messages.findIndex(m => m.role === 'bot-thinking');
                if (thinkingIndex !== -1) this.messages.splice(thinkingIndex, 1);
            },

            addMessage(content, role) {
                const messageId = Date.now() + Math.random();
                this.messages.push({ id: messageId, content, role });

                this.$nextTick(() => {
                    this.$refs.messagesContainer?.scrollTo({ top: this.$refs.messagesContainer.scrollHeight, behavior: 'smooth' });
                });
            },
            
            async handleControlClick(action, ...args) {
                const actionName = action.charAt(0).toUpperCase() + action.slice(1).replace(/([A-Z])/g, ' $1').trim();
                this.updateStatus(`üöÄ Executing: ${actionName}...`);
                this.addMessage({type:'text', content:`Executing command: <strong>${actionName}</strong>`}, 'bot');
                
                try {
                    if (typeof window.olympus.functions[action] !== 'function') throw new Error(`Control function ${action} not available.`);
                    
                    let result;
                    if (action === 'trainModels') {
                        result = await window.olympus.functions[action]((status) => {
                            this.updateStatus(`[TRAINING] ${status}`);
                        });
                        this.addMessage({type:'text', content:`‚úÖ Action <strong>${actionName}</strong> completed.`}, 'bot');
                    } else {
                        result = await window.olympus.functions[action](...args);
                        this.updateStatus(`‚úÖ ${result}`);
                        this.addMessage({type:'text', content:`‚úÖ Command <strong>${actionName}</strong> successful.<br><span class='text-gray-400'>${result}</span>`}, 'bot');
                    }
                } catch (error) {
                    const errorMsg = `‚ùå Action failed: ${actionName} - ${error.message}`;
                    this.updateStatus(errorMsg);
                    this.addMessage({type:'text', content: errorMsg }, 'bot-error');
                    console.error(error);
                }
            },
            
            resizeTextarea() {
                const textarea = this.$refs.textarea;
                if (!textarea) return;
                textarea.style.height = 'auto';
                textarea.style.height = `${textarea.scrollHeight}px`;
            }
        }));
    });

    window.addEventListener('DOMContentLoaded', () => {
        const container = document.getElementById('three-bg');
        if (!container) return;

        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
        
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(window.devicePixelRatio);
        container.appendChild(renderer.domElement);

        const geometry = new THREE.BufferGeometry();
        const count = 3000;
        const positions = new Float32Array(count * 3);
        const colors = new Float32Array(count * 3);

        for(let i = 0; i < count * 3; i++) {
            positions[i] = (Math.random() - 0.5) * 15;
            colors[i] = Math.random() * 0.5 + 0.5; // Brighter colors
        }

        geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
        geometry.setAttribute('color', new THREE.BufferAttribute(colors, 3));


        const material = new THREE.PointsMaterial({
            size: 0.02,
            vertexColors: true,
            transparent: true,
            opacity: 0.8,
            blending: THREE.AdditiveBlending
        });

        const points = new THREE.Points(geometry, material);
        scene.add(points);

        camera.position.z = 5;

        const mouse = new THREE.Vector2();
        window.addEventListener('mousemove', (event) => {
            mouse.x = (event.clientX / window.innerWidth) * 2 - 1;
            mouse.y = -(event.clientY / window.innerHeight) * 2 + 1;
        }, { passive: true });
        
        const clock = new THREE.Clock();
        function animate() {
            requestAnimationFrame(animate);
            const elapsedTime = clock.getElapsedTime();
            points.rotation.y = elapsedTime * 0.1;
            
            camera.position.x += (mouse.x * 0.5 - camera.position.x) * 0.02;
            camera.position.y += (mouse.y * 0.5 - camera.position.y) * 0.02;
            camera.lookAt(scene.position);

            renderer.render(scene, camera);
        }

        animate();

        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });
    });
  </script>
</body>
</html>